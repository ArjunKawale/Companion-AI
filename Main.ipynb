{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "762f1f9c",
   "metadata": {},
   "source": [
    "# **AI Companion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8b5a0a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b177fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from google import genai\n",
    "import json\n",
    "from Memory.extractor import extract_memory\n",
    "from Memory.store import MemoryStore\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "client = genai.Client(api_key=api_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e0ef48",
   "metadata": {},
   "source": [
    "## Load Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06f0e9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MESSAGE: Bro I think I like dark themes too much, every app I use is in dark mode lol.\n",
      "Extracted: preferences=[UserPreference(category='theme_preference', value='dark mode', confidence=1.0)] emotional_patterns=[] facts=[]\n",
      "\n",
      "=== MESSAGE: I'm trying to get into ML but sometimes it just feels overwhelming ngl.\n",
      "Extracted: preferences=[] emotional_patterns=[EmotionalPattern(emotion='overwhelmed', trigger='learning machine learning', confidence=0.8)] facts=[]\n",
      "\n",
      "=== MESSAGE: Btw remind me, I prefer short explanations over long essays.\n",
      "Extracted: preferences=[UserPreference(category='communication_style', value='prefers short explanations', confidence=1.0)] emotional_patterns=[] facts=[]\n",
      "\n",
      "=== MESSAGE: Today was exhausting, college labs were so boring.\n",
      "Extracted: preferences=[UserPreference(category='activity_engagement', value='dislikes boring activities', confidence=0.8)] emotional_patterns=[EmotionalPattern(emotion='exhaustion', trigger='boring college labs', confidence=0.7)] facts=[]\n",
      "\n",
      "=== MESSAGE: My fav snacks are literally chips and cold coffee haha.\n",
      "Extracted: preferences=[UserPreference(category='snacks', value='chips', confidence=1.0), UserPreference(category='beverages', value='cold coffee', confidence=1.0)] emotional_patterns=[] facts=[]\n",
      "\n",
      "...\n",
      "\n",
      "=== FINAL MEMORY STORE SAVED TO D:\\Companion_AI\\Memory\\memory_store.json ===\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "JSON_PATH = r\"D:\\Companion_AI\\Conversation_Data\\conv.json\"\n",
    "OUTPUT_PATH = r\"D:\\Companion_AI\\Memory\\memory_store.json\"\n",
    "\n",
    "# Load conversation data\n",
    "with open(JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "store = MemoryStore()\n",
    "\n",
    "# Extract memory for first 5 messages only\n",
    "for i, item in enumerate(data):\n",
    "    if i < 5:\n",
    "        msg = item[\"text\"]\n",
    "        print(\"\\n=== MESSAGE:\", msg)\n",
    "\n",
    "        try:\n",
    "            extracted = extract_memory(msg)\n",
    "            print(\"Extracted:\", extracted)\n",
    "            store.add_memory(extracted)\n",
    "        except Exception:\n",
    "            # Skip error printing for now\n",
    "            continue\n",
    "    else:\n",
    "        print(\"\\n...\")  # Indicate there are more messages\n",
    "        break\n",
    "\n",
    "# Save final memory store to JSON\n",
    "with open(OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(store.get_all(), f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\n=== FINAL MEMORY STORE SAVED TO {OUTPUT_PATH} ===\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "211b89e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from personality import PersonalityEngine, PERSONALITY_PROMPTS\n",
    "\n",
    "MEMORY_PATH = r\"D:\\Companion_AI\\Memory\\memory_store.json\"\n",
    "\n",
    "with open(MEMORY_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    user_memory = json.load(f)\n",
    "\n",
    "engine = PersonalityEngine(user_memory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0221c4",
   "metadata": {},
   "source": [
    "# Normal AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6f2810c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== User Message: I'm feeling overwhelmed with my ML project. ===\n",
      "\n",
      "\n",
      "--- Normal AI Response ---\n",
      "\n",
      "I get it, ML projects can be a lot. When you're feeling overwhelmed, it's usually best to break things down into small, actionable steps. Instead of looking at the whole project, what's just one tiny thing you can tackle right now? Maybe just setting up your environment, or reviewing the first section of your notes (the super organized ones, I bet!).\n",
      "\n",
      "And hey, if you need some lo-fi to code to, or want to talk about a sci-fi movie to clear your head, let me know. Sometimes solving those 2-day stuck problems comes from stepping away for a bit.\n"
     ]
    }
   ],
   "source": [
    "# User input\n",
    "user_message = \"I'm feeling overwhelmed with my ML project.\"\n",
    "\n",
    "print(f\"\\n=== User Message: {user_message} ===\\n\")\n",
    "\n",
    "# Normal / neutral response (uses memory but no personality style)\n",
    "response = engine.respond(user_message, style=\"normal\")  \n",
    "# Print response\n",
    "print(\"\\n--- Normal AI Response ---\\n\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d185bce2",
   "metadata": {},
   "source": [
    "# Calm Mentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c826cb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Personality: calm_mentor ---\n",
      "I understand that feeling, it's quite common when diving into machine learning projects. Remember that time you solved that two-day coding problem? That showed incredible persistence, and you've got that same strength to tackle this.\n",
      "\n",
      "Breaking things down into smaller, actionable steps often helps. Instead of looking at the whole project, perhaps we could focus on just one component? What's the very next, smallest thing you need to achieve?\n",
      "\n",
      "You're learning FastAPI and React, which are big steps, and you've shown you can handle new challenges. Let's apply that same structured approach here. We can figure this out together.\n"
     ]
    }
   ],
   "source": [
    "user_message = \"I'm feeling overwhelmed with my ML project.\"\n",
    "\n",
    "response = engine.respond(user_message, style=\"calm_mentor\")\n",
    "print(f\"\\n--- Personality: calm_mentor ---\\n{response}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954b957b",
   "metadata": {},
   "source": [
    "# Witty Friend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfb77cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Personality: witty_friend ---\n",
      "Ugh, the ML monster strikes again, huh? Been there, done that, bought the \"my code is broken and I don't know why\" t-shirt. Remember that time your Wi-Fi decided to ghost you at 1 AM, right when you were in the zone? This feels kinda similar, but with more math.\n",
      "\n",
      "Look, you're the person who *solves* those two-day long problems, so I know you've got this. And hey, even if it feels like trying to debug a black hole, we can totally break it down into some small, actionable steps. Maybe a cold coffee (or two) and some lo-fi beats will help untangle the brain-spaghetti. We'll get through this, one tiny, less overwhelming piece at a time. No boring stuff allowed, obviously.\n"
     ]
    }
   ],
   "source": [
    "user_message = \"I'm feeling overwhelmed with my ML project.\"\n",
    "\n",
    "response = engine.respond(user_message, style=\"witty_friend\")\n",
    "print(f\"\\n--- Personality: witty_friend ---\\n{response}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c2d6d9",
   "metadata": {},
   "source": [
    "# Therapist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8ca1072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Personality: therapist ---\n",
      "Hey there, I hear you. Feeling overwhelmed when tackling something as complex as an ML project is completely understandable. It sounds like a lot to juggle right now. Remember how you sometimes feel overwhelmed when learning machine learning, and it's totally normal for this kind of challenge.\n",
      "\n",
      "Let's take a deep breath. Instead of looking at the whole mountain, how about we break it down into some smaller, more manageable steps? You know how much you prefer small, actionable steps for motivation, right?\n",
      "\n",
      "What's one tiny thing, maybe just a 15-minute task, that you could focus on for your ML project right now? Something that doesn't feel like a huge commitment, but gets you moving forward. We can figure it out together.\n"
     ]
    }
   ],
   "source": [
    "user_message = \"I'm feeling overwhelmed with my ML project.\"\n",
    "\n",
    "response = engine.respond(user_message, style=\"therapist\")\n",
    "print(f\"\\n--- Personality: therapist ---\\n{response}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
